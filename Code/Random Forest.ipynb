{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0f44c-e12b-42db-91c8-76e3263c3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, f1_score,\n",
    "                             matthews_corrcoef, roc_curve, roc_auc_score, precision_recall_curve)\n",
    "\n",
    "# Load data from CSV file\n",
    "file_path = \"data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the last column is the target variable and all other columns are features\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "Y_pred = rf_classifier.predict(X_test)\n",
    "Y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(Y_test, Y_pred)\n",
    "\n",
    "# Sensitivity, Specificity, and other metrics from confusion matrix\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "recall = sensitivity  # Recall is the same as sensitivity\n",
    "\n",
    "# Print out metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "#  Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "#  ROC Curve\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve (AUC = {:.2f})'.format(roc_auc_score(Y_test, Y_pred_proba)))\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#  Precision-Recall Curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(Y_test, Y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_curve, precision_curve, color='green', label='Precision-Recall Curve')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "importances = rf_classifier.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.barh(range(X.shape[1]), importances[indices], align='center')\n",
    "plt.yticks(range(X.shape[1]), [f'Feature {i}' for i in indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance in Random Forest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "#  Distribution of Predicted Probabilities\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(Y_pred_proba, bins=30, kde=True, color='purple')\n",
    "plt.title('Distribution of Predicted Probabilities')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#  Pairplot of Features\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.pairplot(data.iloc[:, :-1].assign(Target=Y))\n",
    "plt.title('Pairplot of Features')\n",
    "plt.show()\n",
    "\n",
    "#  Boxplot of Features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(data=data.iloc[:, :-1])\n",
    "plt.title('Boxplot of Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "#  Violin Plot of Feature Distributions by Target\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.violinplot(x=Y, y=data.iloc[:, :-1].values.flatten(), scale='width')\n",
    "plt.title('Violin Plot of Feature Distributions by Target')\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = data.iloc[:, :-1].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "#  Learning Curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(rf_classifier, X, Y, cv=5, scoring='accuracy', \n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training Accuracy')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='red', label='Validation Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
